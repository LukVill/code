qz <- gradebook %>% select(c("UID","Quiz_1","Quiz_2","Quiz_3","Quiz_4","Quiz_5")) %>% pivot_longer(c("Quiz_1","Quiz_2","Quiz_3","Quiz_4","Quiz_5"), names_to = "Quiz_Num", values_to = "Q_Score") %>% mutate(order_num = as.numeric(substr(Quiz_Num,6,length(Quiz_Num))))
res <- hw %>% left_join(qz, by = c("UID","order_num")) %>% select(c("UID", "order_num","HW_Score", "Q_Score")) %>% rename(Assgn_Num = order_num, Homework = HW_Score, Quiz = Q_Score)
return(res)
}
gradebook_tidy <- tidify_gradebook()
print("Students with Nulls:")
hw_na <- gradebook_tidy %>% filter(is.na(Homework)) %>% slice(1:2)
qz_na <- gradebook_tidy %>% filter(is.na(Quiz)) %>% slice(1:2)
students_na_ex <- rbind(hw_na,qz_na)
tidy_impute(students_na_ex,"mean", 1)
tidy_impute(students_na_ex,"mean", 2)
tidy_impute(students_na_ex, "median", 1)
tidy_impute(students_na_ex, "median", 2)
tidy_impute(students_na_ex, "mean", 1, trim = 0.25)
tidy_impute(students_na_ex, "mean", 2, trim = 0.25)
library(stringr)
library(tidyverse)
library(tidyr)
source("206039397_stats102a_hw2.R")
gradebook <- gen_gradebook()
# randomly replace data in vector with NA
# percent is inputted as an integer
# function will AT LEAST make the NA percent, but it can over do it
na.replace <- function(vec,percent = 10)
{
# function to pick random index in vec
get_random_index <- function(vec)
{
floor(runif(1,min = 1, max = length(vec)+1))
}
# result vector
res <- vec
# default of percent is 10
# input validation for percent
if(!is.numeric(percent))
{
stop("inputted percent is not numeric")
}
if(length(percent) != 1)
{
stop("inputted percent is a vector, and should be one value")
}
# input validation for vec
# send warning if there are na's in vec already, telling user
# that those na's will count too
if(any(is.na(vec)))
{warning("there exists NA's in inputted vector.
These NA's will count towards the percentage of NA's")}
# check if percent is inputted as a decimal
if(percent %% 1 != 0)
{stop("inputted percent is decimal, but should be integer")}
# check if percent is negative
if(percent < 0)
{stop("inputted percent should be nonnegative")}
# check if percent is 0
if(percent == 0)
{warning("inputted percent is 0, should be positive; function will still run")}
# check if percent is bigger than 100 percent
if(percent > 100)
{stop("inputted percent is greater than 100, should be from 1-100")}
# get how many to change to reach at least 10 percent
percent <- percent / 100
# round up to get AT LEAST percent
needed_nas <- ceiling(percent * length(vec))
# count how many NAs, subtract current NA's from
n_na <- length(which(is.na(vec)))
# get percentage of NA's left to do
na_left <- needed_nas - n_na
# while there are na left to make
while(na_left > 0)
{
# get random indx
indx <- NA
# check if not already NA
while(is.na(indx))
{indx <- get_random_index(vec)}
# once we get here, indx is not NA, so change to NA
res[indx] <- NA
# update na_left counter
na_left <- na_left - 1
}
# no more needed na's, so return vec
return(res)
}
gradebook$Homework_4 <- na.replace(gradebook$Homework_4,10)
gradebook$Quiz_4 <- na.replace(gradebook$Quiz_4,10)
# show there are 10 na's in specific columns
sum(is.na(gradebook$Homework_4))
sum(is.na(gradebook$Quiz_4))
# selecting and printing two students with missing HW 4 and missing Q4
print("Students missing Homework_4:")
print(gradebook %>% filter(is.na(Homework_4)) %>% slice(1:2))
print("Students missing Quiz_4:")
print(gradebook %>% filter(is.na(Quiz_4)) %>% slice(1:2))
# messy_impute cases
messy_impute(gradebook,"mean", 1)
messy_impute(gradebook,"mean", 2)
messy_impute(gradebook, "median", 1)
messy_impute(gradebook, "median", 2)
messy_impute(gradebook, "mean", 1, trim = 0.25)
messy_impute(gradebook, "mean", 2, trim = 0.25)
# assumes there is gradebook name
tidify_gradebook <- function()
{
# INPUT VALIDATION
if(!exists("gradebook"))
{stop("there should exists a \"gradebook\" object that holds UID, Homeworks, Quizzes")}
# work with homework, mutate order of homework
hw <- gradebook %>% select(c("UID","Homework_1","Homework_2","Homework_3","Homework_4","Homework_5")) %>% pivot_longer(c("Homework_1","Homework_2","Homework_3","Homework_4","Homework_5"), names_to = "Homework_Num", values_to = "HW_Score") %>% mutate(order_num = as.numeric(substr(Homework_Num,10,length(Homework_Num))))
# work with quizzes, mutate order
qz <- gradebook %>% select(c("UID","Quiz_1","Quiz_2","Quiz_3","Quiz_4","Quiz_5")) %>% pivot_longer(c("Quiz_1","Quiz_2","Quiz_3","Quiz_4","Quiz_5"), names_to = "Quiz_Num", values_to = "Q_Score") %>% mutate(order_num = as.numeric(substr(Quiz_Num,6,length(Quiz_Num))))
res <- hw %>% left_join(qz, by = c("UID","order_num")) %>% select(c("UID", "order_num","HW_Score", "Q_Score")) %>% rename(Assgn_Num = order_num, Homework = HW_Score, Quiz = Q_Score)
return(res)
}
gradebook_tidy <- tidify_gradebook()
print("Students with Nulls:")
hw_na <- gradebook_tidy %>% filter(is.na(Homework)) %>% slice(1:2)
qz_na <- gradebook_tidy %>% filter(is.na(Quiz)) %>% slice(1:2)
students_na_ex <- rbind(hw_na,qz_na)
students_na_ex
tidy_impute(students_na_ex,"mean", 1)
tidy_impute(students_na_ex,"mean", 2)
tidy_impute(students_na_ex, "median", 1)
tidy_impute(students_na_ex, "median", 2)
tidy_impute(students_na_ex, "mean", 1, trim = 0.25)
tidy_impute(students_na_ex, "mean", 2, trim = 0.25)
# get UID of example students
na_uids <- gradebook_tidy %>% filter(is.na(Homework)) %>% slice(1:2) %>% select(UID)
na_uids
# get UID of example students
na_uids <- gradebook_tidy %>% filter(is.na(Homework)) %>% slice(1:2) %>% pull(UID)
na_uids
na_uids <- c(na_uids, gradebook_tidy %>% filter(is.na(Quiz)) %>% slice(1:2) %>% pull(UID))
na_uids
# get indices of example students
which(gradebook_tidy$UID == na_uids)
# get indices of example students
gradebook_tidy[which(gradebook_tidy$UID == na_uids)]
# get indices of example students
gradebook_tidy[which(gradebook_tidy$UID == na_uids),]
na_uids
# get indices of example students
gradebook_tidy[which(gradebook_tidy$UID == na_uids),]
gradebook_tidy %>% filter(is.na(Homework)) %>% slice(1:2)
# get indices of example students
gradebook_tidy[which(gradebook_tidy$UID == na_uids),]
# get indices of example students
gradebook_tidy[which(gradebook_tidy$UID == na_uids & (is.na(gradebook_tidy$Homework) | is.na(gradebook_tidy$Quiz))),]
# get indices of example students
rownames(gradebook_tidy)
# get UID of example students
na_uids <- gradebook_tidy %>% filter(is.na(Homework)) %>% slice(1:2) %>% select(UID)
rownames(na_uids)
# get UID of example students
na_uids <- gradebook_tidy %>% filter(is.na(Homework)) %>% slice(1:2)
rownames(na_uids)
gradebook_tidy %>% filter(is.na(Homework)) %>% slice(1:2)
gradebook_tidy %>% mutate(index = rownames(gradebook_tidy)
gradebook_tidy %>% mutate(index = rownames(gradebook_tidy))
# get UID of example students
na_uids <- gradebook_tidy %>% mutate(index = rownames(gradebook_tidy)) %>% filter(is.na(Homework)) %>% slice(1:2)
na_uids
na_uids <- c(na_uids, gradebook_tidy %>% mutate(index = rownames(gradebook_tidy)) %>% filter(is.na(Quiz)) %>% slice(1:2) %>% pull(UID))
na_uids
# get UID of example students
na_uids <- gradebook_tidy %>% mutate(index = rownames(gradebook_tidy)) %>% filter(is.na(Homework)) %>% slice(1:2)
na_uids
na_uids <- c(na_uids, gradebook_tidy %>% mutate(index = rownames(gradebook_tidy)) %>% filter(is.na(Quiz)) %>% slice(1:2))
na_uids
# get UID of example students
na_uids <- gradebook_tidy %>% mutate(index = rownames(gradebook_tidy)) %>% filter(is.na(Homework)) %>% slice(1:2)
na_uids <- rbind(na_uids, gradebook_tidy %>% mutate(index = rownames(gradebook_tidy)) %>% filter(is.na(Quiz)) %>% slice(1:2))
na_uids
# get indices of example students
indx <- na_uids %>% pull(index)
indx
gdbk_indx <- gradebook_tidy %>% mutate(index = rownames(gradebook_tidy))
tidy_impute(gradebook_tidy,"mean", 1)
tidy_impute(gradebook_tidy,"mean", 1) %>% mutate(index = rownames(gradebook_tidy)) %>% slice(indx) %>% select(-index)
tidy_impute(gradebook_tidy,"mean", 1) %>% mutate(index = rownames(gradebook_tidy))
tidy_impute(gradebook_tidy,"mean", 1) %>% mutate(index = rownames(gradebook_tidy)) %>% slice(indx)
indx
tidy_impute(gradebook_tidy,"mean", 1) %>% mutate(index = rownames(gradebook_tidy))
tidy_impute(gradebook_tidy,"mean", 1) %>% mutate(index = rownames(gradebook_tidy)) %>% slice(index == indx)
# get indices of example students
indx <- as.numeric(na_uids %>% pull(index))
indx
tidy_impute(gradebook_tidy,"mean", 1) %>% mutate(index = as.numeric(rownames(gradebook_tidy))) %>% slice(index == indx)
tidy_impute(gradebook_tidy,"mean", 1) %>% mutate(index = as.numeric(rownames(gradebook_tidy))) %>% slice(indx)
tidy_impute(gradebook_tidy,"mean", 1) %>% mutate(index = as.numeric(rownames(gradebook_tidy))) %>% slice(indx) %>% select(-index)
tidy_impute(gradebook_tidy,"mean", 1) %>% mutate(index = as.numeric(rownames(gradebook_tidy))) %>% slice(indx) %>% select(-index)
tidy_impute(gradebook_tidy,"mean", 2) %>% mutate(index = as.numeric(rownames(gradebook_tidy))) %>% slice(indx) %>% select(-index)
tidy_impute(gradebook_tidy, "median", 1) %>% mutate(index = as.numeric(rownames(gradebook_tidy))) %>% slice(indx) %>% select(-index)
tidy_impute(gradebook_tidy, "median", 2) %>% mutate(index = as.numeric(rownames(gradebook_tidy))) %>% slice(indx) %>% select(-index)
tidy_impute(gradebook_tidy, "mean", 1, trim = 0.25) %>% mutate(index = as.numeric(rownames(gradebook_tidy))) %>% slice(indx) %>% select(-index)
tidy_impute(gradebook_tidy, "mean", 2, trim = 0.25) %>% mutate(index = as.numeric(rownames(gradebook_tidy))) %>% slice(indx) %>% select(-index)
setwd("C:/Users/lavil/source/repos/LukVill/code/R/stats102a/206039397_stats102a_hw2")
gdp <- read_csv("gdp-countries.csv")
gdp
web <- read_csv("Most Popular websites.csv")
web
watch <- read_csv("swiss watch brands.csv")
watch
web
web
gdp <- read_csv("gdp-countries.csv")
gdp
# get UID of example students
na_uids <- gradebook %>% mutate(index = rownames(gradebook)) %>% filter(is.na(Homework_4)) %>% slice(1:2)
na_uids <- rbind(na_uids, gradebook %>% mutate(index = rownames(gradebook)) %>% filter(is.na(Quiz_4)) %>% slice(1:2))
na_uids
# get indices of example students
indx <- as.numeric(na_uids %>% pull(index))
# messy_impute cases
messy_impute(gradebook,"mean", 1) %>% mutate(index = as.numeric(rownames(gradebook))) %>% slice(indx) %>% select(-index)
gdp <- read.csv("gdp-countries.csv")
web <- read.csv("Most Popular websites.csv")
watch <- read.csv("swiss watch brands.csv")
gdp
web
watch
watch <- read.csv("swiss watch brands.csv")
watch
web
# display 10 observations
print(gdp[1:10,])
print(web[1:10])
print(watch[1:10])
print(web[1:10],)
# display 10 observations
print(gdp[1:10,])
print(web[1:10,])
print(watch[1:10,])
gdp
sampGdp <- gdp[1:10,]
sampWeb <- web[1:10,]
sampWatch <- watch[1:10,]
print(sampWatch)
sampGdp
sampGdp %>% pivot_longer(colnames(sampGdp), names_to = "Countries", values_to = "GDP")
sampGdp
sampGdp %>% pivot_longer(colnames(sampGdp), names_to = "Countries", values_to = "GDP")
sampGdp %>% mutate(time = rownames(sampGdp)
sampGdp %>% mutate(time = rownames(sampGdp)
sampGdp %>% mutate(time = rownames(sampGdp))
# add indexer
sampGdp %>% mutate(time = as.numeric(rownames(sampGdp))) %>% pivot_longer(colnames(sampGdp), names_to = "Countries", values_to = "GDP")
# add indexer, pivot columns
print(sampGdp %>% mutate(time = as.numeric(rownames(sampGdp))) %>% pivot_longer(colnames(sampGdp), names_to = "Countries", values_to = "GDP"), n = 10)
# add indexer, pivot columns
print(sampGdp %>% mutate(time = as.numeric(rownames(sampGdp))) %>% pivot_longer(colnames(sampGdp), names_to = "Countries", values_to = "GDP"), n = 15)
# add indexer, pivot columns
print((sampGdp %>% mutate(time = as.numeric(rownames(sampGdp))) %>% pivot_longer(colnames(sampGdp), names_to = "Countries", values_to = "GDP")), n =10)
# add indexer, pivot columns
print((sampGdp %>% mutate(time = as.numeric(rownames(sampGdp))) %>% pivot_longer(colnames(sampGdp), names_to = "Countries", values_to = "GDP"))[1:10])
# add indexer, pivot columns
print((sampGdp %>% mutate(time = as.numeric(rownames(sampGdp))) %>% pivot_longer(colnames(sampGdp), names_to = "Countries", values_to = "GDP"))[1:10,])
web
colnames(web)[-c(1,2)]
web %>% pivot_longer(colnames(web)[-c(1,2)], names_to = "Years", values_to = "Popularity")
print((web %>% pivot_longer(colnames(web)[-c(1,2)], names_to = "Years", values_to = "Popularity"))[1:10,])
print((web %>% pivot_longer(colnames(web)[-c(1,2)], names_to = "Years", values_to = "Popularity") %>% )[1:10,])
print((web %>% pivot_longer(colnames(web)[-c(1,2)], names_to = "Years", values_to = "Popularity") %>% mutate(Years = substr(Years,2:length(Years))))[1:10,])
print((web %>% pivot_longer(colnames(web)[-c(1,2)], names_to = "Years", values_to = "Popularity") %>% mutate(Years = substr(Years,2,length(Years))))[1:10,])
sampWatch
sampWatch %>% pivot_longer(colnames(sampWatch)[-c(1,2)])
sampWatch %>% pivot_longer(colnames(sampWatch)[-c(1,2)], names_to = "Years", values_to = "Measure")
sampWatch %>% pivot_longer(colnames(sampWatch)[-c(1,2)], names_to = "Years", values_to = "Measure") %>% mutate(Years = substr(Years,2,length(Years))
sampWatch %>% pivot_longer(colnames(sampWatch)[-c(1,2)], names_to = "Years", values_to = "Measure") %>% mutate(Years = substr(Years,2,length(Years))
sampWatch %>% pivot_longer(colnames(sampWatch)[-c(1,2)], names_to = "Years", values_to = "Measure") %>% mutate(Years = substr(Years,2,length(Years)))
(sampWatch %>% pivot_longer(colnames(sampWatch)[-c(1,2)], names_to = "Years", values_to = "Measure") %>% mutate(Years = substr(Years,2,length(Years))))[1:10,]
# print first 10 rows
print((sampWatch %>% pivot_longer(colnames(sampWatch)[-c(1,2)], names_to = "Years", values_to = "Measure") %>% mutate(Years = substr(Years,2,length(Years))))[1:10,])
glimpse(sampGdp)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(linewidth=80)
library(knitr)
hook_output = knit_hooks$get("output")
knit_hooks$set(output = function(x, options)
{
# this hook is used only when the linewidth option is not NULL
if (!is.null(n <- options$linewidth))
{
x = knitr:::split_lines(x)
# any lines wider than n should be wrapped
if (any(nchar(x) > n))
x = strwrap(x, width = n)
x = paste(x, collapse = "\n")
}
hook_output(x, options)
})
library(data.table)
library(ggplot2)
library(tidyr)
library(tidyverse)
library(ggplot2)
# Over to you! Fill in the path to your working directory. If you are on a Windows machine, you will need to use forward slashes (/) instead of backshashes (\)
# SET FILEPATH AS QUANTIUM-PROGRAM
filePath <- paste0(getwd(),"/")
data <- fread(paste0(filePath,"QVI_data.csv"))
#### Set themes for plots
theme_set(theme_bw())
theme_update(plot.title = element_text(hjust = 0.5))
#### Calculate these measures over time for each store
#### Over to you! Add a new month ID column in the data with the format yyyymm.
data[, YEARMONTH := as.numeric(format(data$DATE, "%Y%m"))]
#### Next, we define the measure calculations to use during the analysis.
# Over to you! For each store and month calculate total sales, number of customers, transactions per customer, chips per customer and the average price per unit.
## Hint: you can use uniqueN() to count distinct values in a column
unique_store <- unique(data$STORE_NBR)[order(unique(data$STORE_NBR))]
unique_month <- unique(data$YEARMONTH)[order(unique(data$YEARMONTH))]
measureOverTime <- data %>% group_by(STORE_NBR,YEARMONTH) %>% arrange(STORE_NBR,YEARMONTH) %>% summarize(totSales = sum(TOT_SALES), nCustomers = uniqueN(LYLTY_CARD_NBR), nTxnPerCust = n()/uniqueN(LYLTY_CARD_NBR), nChipsPerTxn = sum(PROD_QTY)/n(), avgPricePerUnit = sum(TOT_SALES)/sum(PROD_QTY))
#### Filter to the pre-trial period and stores with full observation periods
storesWithFullObs <- measureOverTime %>% group_by(STORE_NBR) %>% count() %>% filter(n == 12) %>% pull(STORE_NBR)
preTrialMeasures <- measureOverTime %>% filter(YEARMONTH < 201902 & STORE_NBR %in% storesWithFullObs)
#### Over to you! Create a function to calculate correlation for a measure, looping through each control store.
#### Let's define inputTable as a metric table with potential comparison stores, metricCol as the store metric used to calculate correlation on, and storeComparison as the store number of the trial store.
# pretrialmeasures is inputTable
calculateCorrelation <- function(inputTable, metricCol, storeComparison) {
calcCorrTable <- data.table(Store1 = numeric(), Store2 = numeric(), corr_measure = numeric())
storeNumbers <- unique(inputTable$STORE_NBR)
# compare to each store in pretrialmeasures
for (i in storeNumbers) {
calculatedMeasure <- data.table("Store1" = storeComparison,
"Store2" = i,
"corr_measure" = cor(inputTable %>% filter(STORE_NBR == storeComparison) %>% pull(metricCol), inputTable %>% filter(STORE_NBR == i) %>% pull(metricCol)))
calcCorrTable <- rbind(calcCorrTable, calculatedMeasure)
}
return(calcCorrTable)
}
#### Create a function to calculate a standardised magnitude distance for a measure,
#### looping through each control store
calculateMagnitudeDistance <- function(inputTable, metricCol, storeComparison) {
calcDistTable = data.table("Store1" = numeric(), "Store2" = numeric(), "YEARMONTH" =
numeric(), "measure" = numeric())
storeNumbers <- unique(inputTable$STORE_NBR)
for (i in storeNumbers) {
calculatedMeasure = data.table("Store1" = storeComparison
, "Store2" = i
, "YEARMONTH" = inputTable %>% filter(STORE_NBR == storeComparison) %>% pull(YEARMONTH)
, "measure" = abs(inputTable %>% filter(STORE_NBR == storeComparison) %>% pull(metricCol)
- inputTable %>% filter(STORE_NBR == i) %>% pull(metricCol))
)
calcDistTable <- rbind(as.data.frame(calcDistTable), as.data.frame(calculatedMeasure))
}
#### Standardise the magnitude distance so that the measure ranges from 0 to 1
distTable <- calcDistTable %>% mutate(minDist = min(measure), maxDist = max(measure))
distTable <- distTable %>% mutate(magnitudeMeasure = 1 - (measure - minDist)/(maxDist - minDist))
finalDistTable <- distTable %>% mutate(mag_measure = mean(magnitudeMeasure)) %>% arrange(Store2)
return(finalDistTable)
}
#### Over to you! Use the function you created to calculate correlations against store 77 using total sales and number of customers.
#### Hint: Refer back to the input names of the functions we created.
trial_store <- 77
corr_nSales <- calculateCorrelation(preTrialMeasures, quote(totSales), trial_store)
corr_nCustomers <- calculateCorrelation(preTrialMeasures, quote(nCustomers), trial_store)
#### Then, use the functions for calculating magnitude.
magnitude_nSales <- calculateMagnitudeDistance(preTrialMeasures, quote(totSales),
trial_store)
magnitude_nCustomers <- calculateMagnitudeDistance(preTrialMeasures,
quote(nCustomers), trial_store)
#### Over to you! Create a combined score composed of correlation and magnitude, by first merging the correlations table with the magnitude table.
#### Hint: A simple average on the scores would be 0.5 * corr_measure + 0.5 * mag_measure
corr_weight <- 0.5
score_nSales <- merge(corr_nSales, magnitude_nSales, by = c("Store1","Store2")) %>% mutate(scoreNSales = 0.5 * corr_measure + 0.5 * magnitudeMeasure)
score_nCustomers <- merge(corr_nCustomers, magnitude_nCustomers, by = c("Store1","Store2"))%>% mutate(scoreNCust = 0.5 * corr_measure + 0.5 * magnitudeMeasure)
#### Over to you! Combine scores across the drivers by first merging our sales scores and customer scores into a single table
score_nSales_v1 <- score_nSales %>% select(c("Store1","Store2","scoreNSales"))
score_nCustomers_v1 <- score_nCustomers %>% select(c("Store1","Store2","scoreNCust"))
score_Control <-  cbind(score_nSales_v1, "scoreNCust" = score_nCustomers_v1$scoreNCust)
score_Control <- score_Control %>% mutate(finalControlScore = scoreNSales * 0.5 + scoreNCust * 0.5)
#### Select control stores based on the highest matching store (closest to 1 but
#### not the store itself, i.e. the second ranked highest store)
#### Over to you! Select the most appropriate control store for trial store 77 by finding the store with the highest final score.
control_store <- score_Control %>% filter(Store2 != trial_store) %>% arrange(desc(finalControlScore)) %>% slice(1) %>% pull(Store2)
control_store
#### Visual checks on trends based on the drivers
measureOverTimeSales <- measureOverTime
pastSales <- measureOverTimeSales %>% mutate(Store_type = ifelse(STORE_NBR == trial_store, "Trial", ifelse(STORE_NBR == control_store, "Control", "Other stores")), TransactionMonth = as.Date(paste(YEARMONTH %/% 100, YEARMONTH %% 100, 1, sep = "-"),"%Y-%m-%d")) %>% arrange("YEARMONTH","Store_type") %>% filter(YEARMONTH < 201903)
ggplot(pastSales) + geom_line(aes(TransactionMonth, totSales, color = Store_type)) + labs(x = "Month of operation", y = "Total sales", title = "Total sales by month")
#### Over to you! Conduct visual checks on customer count trends by comparing the trial store to the control store and other stores.
#### Hint: Look at the previous plot.
measureOverTimeCusts <- measureOverTime
pastCustomers <- measureOverTimeCusts %>% mutate(Store_type = ifelse(STORE_NBR == trial_store, "Trial", ifelse(STORE_NBR == control_store, "Control", "Other stores")), TransactionMonth = as.Date(paste(YEARMONTH %/% 100, YEARMONTH %% 100, 1, sep = "-"),"%Y-%m-%d")) %>% arrange("YEARMONTH","Store_type") %>% filter(YEARMONTH < 201903)
ggplot(pastCustomers) + geom_line(aes(TransactionMonth, nCustomers, color = Store_type)) + labs(x = "Month of operation", y = "Total Customers", title = "Total Customers by month")
#### Scale pre-trial control sales to match pre-trial trial store sales
scalingFactorForControlSales <- sum(preTrialMeasures %>% filter(STORE_NBR == trial_store & YEARMONTH < 201902) %>% pull(totSales)) / sum(preTrialMeasures %>% filter(STORE_NBR == control_store & YEARMONTH < 201902))
#### Apply the scaling factor
measureOverTimeSales <- measureOverTime
scaledControlSales <- measureOverTimeSales %>% filter(STORE_NBR == control_store) %>% mutate(controlSales = totSales * scalingFactorForControlSales)
scaledControlSales
scalingFactorForControlSales
measureOverTime
scaledControlSales
measureOverTime
control_store
preTrialMeasures
measureOverTime
#### Over to you! Calculate the percentage difference between scaled control sales and trial sales
preTrialMeasures
measureOverTimeSales
scaledControlSales
measureOverTimeSales
scaledControlSales
measureOverTimeSales
scaledControlSales
colnames(scaledControlSales)
colnames(scaledControlSales)[-8]
measureOverTime %>% right_join(scaledControlSales, by = colnames(scaledControlSales)[-8])
scaledControlSales
measureOverTime %>% filter(STORE_NBR == trial_store)
trial_store
measureOverTime %>% filter(STORE_NBR == trial_store)
scaledControlSales
sum(preTrialMeasures %>% filter(STORE_NBR == control_store & YEARMONTH < 201902) %>% pull(totSales))
sum(preTrialMeasures %>% filter(STORE_NBR == control_store & YEARMONTH < 201902)
sum(preTrialMeasures %>% filter(STORE_NBR == control_store & YEARMONTH < 201902)
sum(preTrialMeasures %>% filter(STORE_NBR == control_store & YEARMONTH < 201902))
sum(preTrialMeasures %>% filter(STORE_NBR == control_store & YEARMONTH < 201902) %>% pull(totSales))
sum(preTrialMeasures %>% filter(STORE_NBR == trial_store & YEARMONTH < 201902) %>% pull(totSales))
#### Scale pre-trial control sales to match pre-trial trial store sales
scalingFactorForControlSales <- sum(preTrialMeasures %>% filter(STORE_NBR == trial_store & YEARMONTH < 201902) %>% pull(totSales)) / sum(preTrialMeasures %>% filter(STORE_NBR == control_store & YEARMONTH < 201902) %>% pull(totSales))
scalingFactorForControlSales
#### Apply the scaling factor
measureOverTimeSales <- measureOverTime
scaledControlSales <- measureOverTimeSales %>% filter(STORE_NBR == control_store) %>% mutate(controlSales = totSales * scalingFactorForControlSales)
scaledControlSales
measureOverTime %>% filter(STORE_NBR == trial_store | STORE_NBR == control_store)
scaledControlSales
#### Over to you! Calculate the percentage difference between scaled control sales and trial sales
measureOverTime
#### Over to you! Calculate the percentage difference between scaled control sales and trial sales
measureOverTime %>% filter(STORE_NBR == trial_store) %>% pull(totSales)
scaledControlSales
percentageDiff <- ((scaledControlSales %>% pull(controlSales))-(measureOverTime %>% filter(STORE_NBR == trial_store) %>% pull(totSales))) / (measureOverTime %>% filter(STORE_NBR == trial_store) %>% pull(totSales))
percentageDiff
percentDiff <- ((scaledControlSales %>% pull(controlSales))-(measureOverTime %>% filter(STORE_NBR == trial_store) %>% pull(totSales))) / (measureOverTime %>% filter(STORE_NBR == trial_store) %>% pull(totSales))
percentageDiff <- scaledControlSales[, percentageDiff = percentDiff]
scaledControlSales
percentageDiff <- scaledControlSales
percentageDiff["percentageDiff"] <- percentDiff
percentageDiff
percentageDiff[YEARMONTH < 201902 , percentageDiff]
percentageDiff["YEARMONTH" < 201902 , "percentageDiff"]
stdDev <- sd(percentageDiff %>% filter(YEARMONTH < 201902) %>% pull(percentageDiff))
percentageDiff %>% filter(YEARMONTH < 201902)
#### Note that there are 8 months in the pre-trial period
#### hence 8 - 1 = 7 degrees of freedom
degreesOfFreedom <- 7
percentageDiff
(measureOverTime %>% filter(STORE_NBR == trial_store & YEARMONTH < 201902) %>% pull(totSales))
(percentageDiff %>% filter(YEARMONTH < 201902) %>% pull(controlSales))
measureOverTime %>% filter(STORE_NBR == trial_store & YEARMONTH < 201902)
percentageDiff %>% filter(YEARMONTH < 201902)
measureOverTime %>% filter(STORE_NBR == trial_store & YEARMONTH < 201902)
percentageDiff %>% filter(YEARMONTH < 201902)
percentageDiff %>% filter(YEARMONTH < 201902) %>% pull(controlSales)
(measureOverTime %>% filter(STORE_NBR == trial_store & YEARMONTH < 201902) %>% pull(totSales))
help(t.test)
t.test((percentageDiff %>% filter(YEARMONTH < 201902) %>% pull(controlSales)),(measureOverTime %>% filter(STORE_NBR == trial_store & YEARMONTH < 201902) %>% pull(totSales)), alternative = "t", var.equal = FALSE, conf.level = 0.95)
t.test((percentageDiff %>% filter(YEARMONTH < 201902) %>% pull(controlSales)),(measureOverTime %>% filter(STORE_NBR == trial_store & YEARMONTH < 201902) %>% pull(totSales)), alternative = "t", var.equal = TRUE, conf.level = 0.95)
t.test((percentageDiff %>% filter(YEARMONTH >= 201902) %>% pull(controlSales)),(measureOverTime %>% filter(STORE_NBR == trial_store & YEARMONTH >= 201902) %>% pull(totSales)), alternative = "t", var.equal = FALSE, conf.level = 0.95)
t.test((percentageDiff %>% filter(YEARMONTH >= 201902) %>% pull(controlSales)),(measureOverTime %>% filter(STORE_NBR == trial_store & YEARMONTH >= 201902) %>% pull(totSales)), alternative = "t", var.equal = TRUE, conf.level = 0.95)
percentageDiff %>% filter(YEARMONTH >= 201902) %>% pull(controlSales)
percentageDiff %>% filter(YEARMONTH >= 201902)
t.test((percentageDiff %>% filter(YEARMONTH >= 201902) %>% pull(controlSales)),(measureOverTime %>% filter(STORE_NBR == trial_store & YEARMONTH >= 201902) %>% pull(totSales)), alternative = "t", var.equal = TRUE, conf.level = 0.95)
percentageDiff %>% filter(YEARMONTH >= 201902) %>% pull(controlSales)
measureOverTime %>% filter(STORE_NBR == trial_store & YEARMONTH >= 201902)
t.test((percentageDiff %>% filter(YEARMONTH >= 201902) %>% pull(controlSales)),(measureOverTime %>% filter(STORE_NBR == trial_store & YEARMONTH >= 201902) %>% pull(totSales)), alternative = "t", var.equal = FALSE, conf.level = 0.95)
t.test((percentageDiff %>% filter(YEARMONTH >= 201902) %>% pull(controlSales)),(measureOverTime %>% filter(STORE_NBR == trial_store & YEARMONTH >= 201902) %>% pull(totSales)), alternative = "t", var.equal = TRUE, conf.level = 0.95)
stdDev <- sd(percentageDiff %>% filter(YEARMONTH < 201902) %>% pull(percentageDiff))
#### Note that there are 8 months in the pre-trial period
#### hence 8 - 1 = 7 degrees of freedom
degreesOfFreedom <- 7
percentageDiff %>% filter(YEARMONTH >= 201902) %>% pull(percentageDiff)
mean(percentageDiff %>% filter(YEARMONTH >= 201902) %>% pull(percentageDiff))/stdDev
tval <- mean(percentageDiff %>% filter(YEARMONTH >= 201902) %>% pull(percentageDiff))/stdDev
pnorm(tval)
help(pnorm)
pt(tval, degreesOfFreedom)
qt(0.95,df = degreesOfFreedom)
tval
qt(0.05,df = degreesOfFreedom)
tval
qt(0.05,df = degreesOfFreedom)
qt(0.05,df = degreesOfFreedom)
qt(0.95,df = degreesOfFreedom)
qt(1,df = degreesOfFreedom)
qt(0.5,df = degreesOfFreedom)
qt(0.4,df = degreesOfFreedom)
qt(0.05,df = degreesOfFreedom)
tval
tval <- mean(percentageDiff %>% filter(YEARMONTH >= 201902) %>% pull(percentageDiff))/sd(percentageDiff %>% filter(YEARMONTH >= 201902) %>% pull(percentageDiff))
tval
tval <- mean(percentageDiff %>% filter(YEARMONTH < 201902) %>% pull(percentageDiff))/sd(percentageDiff %>% filter(YEARMONTH < 201902) %>% pull(percentageDiff))
tval
percentageDiff
control_mean <- percentageDiff %>% filter(YEARMONTH >= 201902) %>% pull(percentageDiff) %>% summarise(mean)
control_mean <- mean(percentageDiff %>% filter(YEARMONTH >= 201902) %>% pull(percentageDiff))
control_mean
percentageDiff
control_mean <- mean(percentageDiff %>% filter(YEARMONTH >= 201902) %>% pull(controlSales))
measureOverTime
trial_mean <- mean(measureOverTime %>% filter(STORE_NBR == trial_store) %>% pull(totSales))
trial_mean <- mean(measureOverTime %>% filter(STORE_NBR == trial_store & YEARMONTH >= 201902) %>% pull(totSales))
trial_mean
control_mean
tval <- (control_mean - trial_mean) / stdDev
tval
tval
qt(0.05,df = degreesOfFreedom)
5+5
